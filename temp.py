from distutils.file_util import write_file
from datasets import load_dataset
from tqdm import tqdm
import numpy as np
import re

Tamil_Dataset = {
    'dataset_name': 'oscar',
    'dataset_subset': 'unshuffled_deduplicated_ta',
    'text_label' : 'text',
    'test_sentence': "рокрпКро┤рпБродрпБ роЪро╛ропрпНроирпНродрпБ ро╡рпЖроХрпБ роирпЗро░рооро╛роХро┐ро╡ро┐роЯрпНроЯродрпБ ЁЯШБ ?",
}
curDataset = Tamil_Dataset
train_dataset = load_dataset(curDataset["dataset_name"] , curDataset["dataset_subset"], split='train[:1]')

import stanza
# stanza.download('ta')       # This downloads the English models for the neural pipeline
nlp = stanza.Pipeline(lang='ta', processors='tokenize,mwt,pos') # This sets up a default neural pipeline in English
write_file = open('temp.txt', 'w')
for sentence in train_dataset:
    print('sentence:', sentence['text'])
    doc = nlp(sentence['text']) 
    for sent in doc.sentences:
        for word in sent.words:
            if(word.pos=='VERB'):
                # print(f'word: {word.text}\tupos: {word.upos}\txpos: {word.xpos}\tfeats: {word.feats if word.feats else "_"}')
                i = word.text
                y= i
                if re.findall("роВродро╛ро│рпН$", i): y=re.sub("роВродро╛ро│рпН$", "ро┐ро░рпБрокроВрокро╛ро│рпН", i)
                elif re.findall("роВродро╛ройрпН$", i): y=re.sub("роВродро╛ройрпН$", "ро┐ро░рпБрокроВрокро╛ро│рпН", i)
                elif re.findall("роВрокро╛ро│рпН$", i): y=re.sub("ро┐ро░рпБрокроВрокро╛ро│рпН$", "роВродро╛ройрпН", i)
                elif re.findall("роВрокро╛ройрпН$", i): y=re.sub("ро┐ро░рпБрокроВрокро╛ройрпН$", "роВродро╛ройрпН", i)
                if re.findall("ро╛ро│рпН$", i): y=re.sub("ро╛ро│рпН$", "родрпБ", i)
                if(i != y):
                    print('i', i, ' y', y)
                elif re.findall("ро╛ройрпН$", i): y=re.sub("ро╛ройрпН$", "родрпБ", i)
                elif re.findall("ройрпН$", i): y=re.sub("ройрпН$", "родрпБ", i)
                elif re.findall("ро│рпН$", i): y=re.sub("ро│рпН$", "родрпБ", i)
                if(i != y):
                    print('i', i, ' y', y)
                if re.findall("ро│рпН$", i): y=re.sub("ро│рпН$", "ро░роВрпзро│роВ", i)
                else: y=re.sub("ройрпН$", "ро░роВрпзро│роВ", i)
                if(i != y):
                    print('i', i, ' y', y)
                
    # doc.sentences[0].print_dependencies()
    # print(*[f'word: {word.text}\tupos: {word.upos}\txpos: {word.xpos}\tfeats: {word.feats if word.feats else "_"}' for sent in doc.sentences for word in sent.words], sep='\n')
    # write_file.write(*[f'word: {word.text}\tupos: {word.upos}\txpos: {word.xpos}\tfeats: {word.feats if word.feats else "_"}' for sent in doc.sentences for word in sent.words], sep='\n')